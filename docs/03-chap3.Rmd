```{r include_packages_2, include = FALSE}
# This chunk ensures that the thesisdown package is
# installed and loaded. This thesisdown package includes
# the template files for the thesis and also two functions
# used for labeling and referencing
if(!require(devtools))
  install.packages("devtools", repos = "http://cran.rstudio.com")
if(!require(dplyr))
    install.packages("dplyr", repos = "http://cran.rstudio.com")
if(!require(ggplot2))
    install.packages("ggplot2", repos = "http://cran.rstudio.com")
if(!require(ggplot2))
    install.packages("bookdown", repos = "http://cran.rstudio.com")
if(!require(thesisdown)){
  library(devtools)
  devtools::install_github("ismayc/thesisdown")
  }
library(thesisdown)
flights <- read.csv("data/flights.csv")
```


# Neurocognitive Theories of Consciousness {#ch3}

Chapter 1 discussed the philosophical notions of consciousness and introduced the questions engrossed the philosophy of mind. The study of consciousness, however, is a multidisciplinary field of research wherein armchair philosophy fails to iron out all the conundrums singlehandedly; no matter what stance we take towards consciousness (eliminative materialism, substance dualism, or anything in between ), we ultimately need to answer the question of how "the mental" interacts with the physical world. The nervous system (more specifically, the brain) is the closest physical entity to the mind. Hence, any account of consciousness must establish (or at least outline) links between the philosophical aspects of consciousness and the neural substrate within (or upon) which it is hosted.

Efforts have been made to bridge between the two disciplines of philosophy (more specifically, what Mandik (2017) calls naturalized philosophy) and neuroscience. Most notably, in her Neurophilosophy, Churchland (1989) attempted to introduce the philosophy of mind to neuroscientists and neuroscience to philosophers (Mandik, 2017). However, most of the contributions to the literature of neurophilosophy are made by philosophers, hence its dominant taste of philosophy. As he notes, neurophilosophy have mainly put three questions in the spotlight: the question of state consciousness (what makes a state conscious?); the question of transitive consciousness (what is the subject of consciousness when one is conscious of it?); and the question of phenomenal character ("when one has a conscious state, in what consists the properties in virtue of which there is something it’s like for one to be in that state?") (Mandik, 2017, p. 460). These questions are referred to as Q_state, $Q_{transitive}$, and Q_{phenomenal} in this dissertation, respectively.

It can be noticed that the study of consciousness among scientists lacks the philosophical accuracy exercised by their philosopher peers. In return, the scientific literature on consciousness is more pragmatic and addresses less abstract problems; more specifically, Qstate and Qphenomenal have received the most attention among neuroscientists. The former has mainly been studied in the research into neural correlates of consciousness (NCCs) while the latter has been the subject matter of models of consciousness. This chapter reviews NCC research and two prominent models of consciousness (viz. the global workspace models and the multiple drafts model). In section 3.2, the global workspace theory of consciousness and its backbone (namely, the global access hypothesis) are reviewed by the relevant body of evidence favoring them. In the same section, Dennett's multiple drafts model is reviewed and compared with the global workspace theory. Finally, in section 3.3, global workspace models are discussed. This chapter is a foundation for Chapter 4, which is about the computational implementations of global workspace models.

## From Neural Correlates to Models of Consciousness

David Chalmers (2010, Chapter 2) has laid down an agenda for the scientific study of consciousness. In his opinion, a scientific account of consciousness needs to, ultimately, relate first-person data of subjective experience to third-person, objective data reflected in observable behaviors or neural processes. He distinguishes six projects for a proper science of consciousness: 1) establishing solid explanations  of third-person data; 2) contrasting conscious and unconscious processes; 3) probing the contents of consciousness; 4) finding neural correlates of consciousness; 5) systemizing the connections between first- and third-person data; and 6) inferring fundamental principles of consciousness (2010, pp. 41–47). His proposal mainly concerns answering the descriptive (Why) questions while leaving aside the explanatory (How) and functional (Why) questions. (cf. Chapter 1).

He, at least implicitly, hopes that having all pieces of the puzzle in place yields an adequate scientific understanding of consciousness; the answers to the How questions, for instance, will be logically entailed if we succeed in stringing the shreds of conscious phenomena (his first five projects) and inferring the constitutional rules of consciousness within this constellation. Some might not find this approach promising—if ever feasible. Nonetheless, it helps us understand why the study of NCCs has become a vital element in the neuroscientific study of consciousness.

NCCs are the neural system(s) or assemblies that can be associated with different aspects of consciousness, e.g., conscious mental states or their contents. This definition posits that NCCs exist somewhere in the brain, and the quest is to find and characterize them. The ultimate goal in the search for NCCs is to use them in the explanations of consciousness, and if that is a viable option, somehow reduce consciousness to its neural correlates. Before doing so, one has to clarify what she means by consciousness, and characterize the association that would count as "correlation." There are several conceptual and methodological obstacles in characterizing NCCs (and making inferences upon them) which are beyond the scope of this chapter (there are entire books on the matter, e.g., Metzinger, 2000). One of the most critical conceptual issues —after defining what does (and does not) count as correlation— is that mere correlations can hardly provide any solid explanation of the origins of the association. (Koch, Massimini, Boly, & Tononi, 2016; Rees & Frith, 2017).

Neural correlates can be defined in (at least) three different ways, based on the notion of consciousness in question. For state consciousness (NCCstate; in line with Qstate) it can be defined as follows:

A neural system N is an NCC if the state of N correlates directly with states of consciousness. (Chalmers, 2010, p. 61)

On the other hand, NCCs of contents of consciousness (NCCcontent; addressing, loosely speaking, Qtransitive) can be defined as:

A neural correlate of the contents of consciousness is a neural representational system N such that representation of a content in N directly correlates with representation of that content in consciousness. (Chalmers, 2010, p. 65)

It is far trickier to answer Qphenomenal through the study of the neural systems associated with the phenomenal properties of consciousness (NCCphenomenal). An NCCphenomenal can be defined as:

A state N1 of system N is a neural correlate of phenomenal property P if N’s being in N1 directly correlates with the subject having P. (Chalmers, 2010, p. 68)

Although NCC research has received much attention, it is crucial to not forget what has made it relevant to consciousness research in the first place: its promise of helping the scientific endeavors in bridging the gap between first- and third-person data. Moreover, it has a (somewhat) strong premise: that the (phenomenal) aspects of consciousness can be reduced to the candidate NCCs. However, it seems NCC research has been more successful in describing the associations between aspects of consciousness and neural phenomena than adequately explaining them. This brings us to models of consciousness, which encompass NCCs within more comprehensive frameworks.

A model of consciousness is a theoretical description of how brain properties relate to phenomenal properties of consciousness using a mechanistic explanation (Seth, 2007; also cf. Chapter 2). The last part of the definition distinguishes models of consciousness from theories of consciousness that do not necessarily commit to establishing a mechanistic understanding of consciousness (Seth, 2007). The term "models of consciousness" has been used slightly differently in the literature of machine consciousness with less commitment to the realization of the model in a neural substrate. For instance, Reggia (2013) deems higher-order thought (HOT) theories (D. Rosenthal, 2005; D. M. Rosenthal, 1996; also cf. Carruthers, 2016) as models of consciousness since they provide a mechanistic explanation of consciousness and can be realized computationally. Conversely, Seth (2007) opposes HOT theories as such since he believes such mechanistic explanation should be anchored to a neural realization in order to count as a model of consciousness. On the other hand, although Seth (2007) includes Dennett's (1993) multiple drafts model among models of consciousness, it is left out in (Reggia, 2013) as it is not clear how this model can be explicitly implemented computationally.

Among the various models of consciousness (cf. e.g., Reggia, 2013; Seth, 2007), two are of greater importance for the subject of this thesis: the global workspace models (GWMs), and the multiple draft model (MDM). GWMs are discussed in details in the next section, and MDM will be briefly introduced accordingly.

## Global Workspace Theory of Consciousness

The global workspace theory (GWT), first presented by Baars (1993) in his magnum opus A Cognitive Theory of Consciousness, initially aimed at contrasting conscious processes from the unconscious ones. It later matured into a comprehensive cognitive theory of consciousness (Baars, 2002) as it received empirical support (Franklin, Strain, Snaider, McCall, & Faghihi, 2012). It is crucial to note that Baars' original (1993) proposal of GWT is a functional theory of consciousness, yet it became a cornerstone for later models of phenomenal consciousness. The GWT assumes the unconscious (background) processes run in parallel in the distributed system of (specialized) processors and it is the "coalitions of these processes [that] enable an agent … to make sense of the sensory data coming from the current environmental situation." (Franklin, 2011, p. 328). Moreover, since numerous processes are simultaneously running in the brain at any given time, different coalitions emerge in the brain, and, as Franklin (2011) puts it,

[These] coalitions, incorporating the results of the processing of sensory data, compete for attention in what Baars calls a global workspace. The contents of the winning coalition are broadcast to all other processes. The contents of this broadcast are proposed to be phenomenally conscious. This conscious broadcast serves to recruit other, unconscious, processes to be used to select an action in response to the current situation. GWT is therefore a theory of how consciousness functions within cognition. (p. 328)

In this theory, the global workspace (GW) acts both as a "bottleneck"  of information and a broadcaster. Figure 3.1 (Franklin et al., 2012, fig. 1) roughly shows how GW filters the competing information "produced" by different sensory coalitions and broadcasts to other areas. It can be generalized to other processes as well. See Figure 3.2 (Shanahan, 2010, fig. 4.1). Before discussing the details of how GWT is realized in the brain, we need to discuss the theoretical and empirical foundations of GWT, to which subsections 3.2.1 and 3.2.2 are dedicated.

### The Conscious Limitedness and The Unconscious Immenseness

The point of departure for GWT is the well-established finding that limited conscious capacity of the brain (e.g., in coherent binding of sensory inputs, conscious access to memory, and cognitively demanding tasks) coexists along with many unconscious, parallel processes (such as coordination of body movements and maintaining balance, or perception of volumes in vision) happening within a "massive beehive of neural assemblies, cells, layers, and connections, each flexibly specialized in some set of tasks." (Baars, 2017, pp. 232–233). The limited conscious capacity has been known to philosophers, psychologists, and cognitive (neuro)scientists for decades. For a detailed review of limited capacity in attention, action, memory, and vision, see (Baars, 1993, secs. 1.3.3-1.3.6). Baars also reviews the consensus around unconscious parallel processes in the brain and discusses their properties (1993, sec. 1.4). For a more concise review, see (Baars, 1997b). GWT suggests the global access hypothesis (GAH) can explain how these different kinds of processes coexist—and interact. Here, two of the most intuitive psychological bodies of evidence for parallel processes are reviewed: the mental lexical access, and the autobiographical memory.

It is estimated that an average 20-year-old native English speaker knows roughly 42,000 unique lemmas (Brysbaert, Stevens, Mandera, & Keuleers, 2016). Many of these lemmas are shared by different words, meaning that the native speaker's lexicon is far more abundant. Moreover, many words with the same morphology differ remarkably in their meanings. It is evident that one does not (and, in fact, cannot) consciously retrieve meanings of every word from her lexicon to comprehend sentences in the everyday use of language. Additionally, there is compelling evidence that the semantic context of words is autonomously (and unconsciously) processed before the correct connotation of the word is (consciously) comprehended. (Swinney, 1979; as cited in Baars, 1993). Baars elaborates on this with an example:

A typical experiment in this literature has the following format: Subjects listen to a sentence fragment ending in an ambiguous word, such as "They all rose …" The word "rose” can be either a verb or a noun, but in this sentence context it must be a verb. How long will it take for this fact to influence the interpretation of the next word? To test this, one of two words is presented, either flower, or stood. Subjects are asked to decide quickly whether the presented word is a real English word or not. If the subjects make use of the sentence context in their lexical decision task, the verb "rose” should speed decisions for "stood," because the two words are similar in meaning and syntax; if the context is not used, there should be no time difference between the verb "stood" and the noun "flower." Several investigators have found that for the first few hundred milliseconds, the sentence context has no influence at all … Thus it seems as if lexical access is autonomous and context-free for a few hundred milliseconds. After this period, prior context does influence the choice of interpretation. (Baars, 1993, p. 46)

More recent research has focused on characterizing the neural processes that give rise to this phenomenon (for recent studies on semantic priming, cf., e.g., Fahimi Hnazaee, Khachatryan, & Van Hulle, 2018; Lerner, Bentin, & Shriki, 2012).

Another interesting phenomenon is the quick accessibility of individual memories within the autobiographical memory. In his classic study, Standing (1973) reports that, under certain measurement conditions, subjects are capable of distinguishing as many as 10,000 images previously seen only for a few seconds each. Based on these findings, Baars writes:

We can get an everyday sense of this remarkable memory performance from the common experience of recognizing a film seen only once, many years ago, with a sudden sense of familiarity. Often we can even predict the next scene. It seems that the brain creates memories of the stream of experience merely by paying attention to it; but humans are always paying attention to new and interesting things, suggesting that our spontaneous autobiographical memory must be very large indeed. Once again we have a vast unconscious domain, and we gain access to it using conscious thought. Mere consciousness of an event helps to store it in memory, and when we experience it again we can voluntarily recognize one distinctive episode from many millions in memory. (2017, p. 234)

### The Global Access Hypothesis

GWT introduces GAH using the classic theater metaphor of consciousness (Baars, 1997a). In this metaphor, the parallel processes compete in order to take over the stage, and the contents of the winner become accessible (or, is "broadcast") to other processes. The working memory is also on the stage; it can be seen as either as a computational resource "within" the GW, available to the winning process, or as a "medium" hosting the information contents of the processes . The content appearing on the stage is experienced consciously by the subject when illuminated by the spotlight fo attention.

Figure 3.3 (adapted from Baars, 2017, fig. 16.1) shows a schematic view of GAH and the stage, the spotlight, and the processes accessing the GW. These processes, both the competitors and the audience —although most of them can undertake both roles— are not limited to sensory inputs and verbal and non-verbal outputs; they can also be related to perceptual and cognitive contexts (examples of the latter are intentions, expectations, and the "self") or the unconscious resources (such as interpretations, memories, language, and automatism).

GAH has received a staggering amount of converging empirical and philosophical support (cf., e.g., Cooney & Gazzaniga, 2003; Dehaene, Kerszberg, & Changeux, 2001; Dehaene, Sergent, & Changeux, 2003; D. Dennett, 2001; Freeman, 2003; as cited in Baars, 2017). Although there are discrepancies in characterization and properties of the "GW" in these theories, there is a decent consensus among scholars around GAH, especially with formalizations close to that of GWT—and such consensuses are quite scarce in the field of consciousness studies. A more detailed review of the literature (from 1983 to 2001) supporting GAH can be found in (Baars, 2002). Before moving on to GWMs (which are realizations of GWT) let us address Daniel Dennett's multiple drafts model as it gives additional insights into the GAH.

### Multiple Drafts Model

Daniel Dennett's MDM (1993; 2001) belongs to (and stands out as an exemplary member of) the family of narrative interpretive theories of consciousness. It was developed as an alternative to the metaphor of "Cartesian Theater" which posits that consciousness is a result of the consolidation of information at some spatial or functional location or in a special mode or format wherein they become accessible to the "self." (Van Gulick, 2018, sec. 9.4). Discussion of Descartes' dualist theory of mind is well beyond this manuscript, but the keen reader can consult (Hatfield, 2018, sec. 3.4; Robinson, 2017, sec. 1.2; Van Gulick, 2018, secs. 4.5, 8.1).

The MDM borrows "elements of both representationalism and higher-order theory but does so in a way that varies interestingly from the more standard versions of either providing a more interpretational and less strongly realist view of consciousness." (Van Gulick, 2018, sec. 9.4, par. 1). The multiple pieces of information made by brain regions are considered "drafts"; passed from one region to another and subject to constant modification as they travel around. Drafts gain "fame" in the brain based on the degree to which they engage the processors. The drafts compete to gain more fame, and content of the most famous draft becomes "conscious." According to MDM, qualia are not phenomena that need explanations but mere epiphenomena of gaining the most fame, hence it is an eliminativists theory of consciousness (Ramsey, 2019, sec. 3.3). This implies that many of the questions mentioned in Chapter 1 are irrelevant—what does it mean to explain something that does not "exist"? MDM also explains the self as a "center of narrative gravity" (D. Dennett, 1992). As Van Gulick (2018) writes,

The MDM treats the self as an emergent  or virtual aspect of the coherent roughly serially narrative that is constructed through the interactive play of contents in the system. Many of those contents are bound together at the intentional level as perceptions or fixations from a relatively unified and temporally extended point of view, i.e., they cohere in their contents as if they were the experiences of [an] ongoing self. But it is the order of dependence that is crucial to the MDM account. The relevant contents are not unified because they are all observed by a single self, but just the converse. It is because they are unified and coherent at the level of content that they count as the experiences of a single self, at least of a single virtual self. (sec. 9.4, para. 3)

The MDM has been extremely controversial yet amazingly influential. One of the most important criticisms against MDM (and more specifically, the way Dennett sells it in his seminal book Consciousness Explained (1993)) is that it, although built upon empirical evidence, fails to provide a realist, scientifically testable  model for consciousness (see, e.g., McGinn, 1995). The keen reader will gain insights into the critiques of the MDM in the peer commentary of Dennett and Kinsbourne's (1992) paper.

The MDM and the GWT both endorse the GAH, but in different ways. The MDM is in line with the GAH, as it emphasizes on the accessibility of the drafts to the processors, but does not set forth any locus where they consolidate—more precisely, it explicitly denies that. The GWT, on the other hand, limits the global accessibility to the content reaching the stage of the GW, while there is no stage in the MDM metaphor. The GWT –even its original version where it has no commitment to any physical realization, see next subsection—  is more "scientific" for at least three reasons: it can be formally defined, beyond metaphorical interpretations; it gives a mechanistic explanation for consciousness; and, most importantly, it makes specific predictions that can be verified scientifically. The GWMs are even more powerful compared to the basic GWT for they discuss realization of the GW, and, one way or another, anchor themselves to the underlying neurobiology and neuroanatomy of the brain. These realizations are discussed in the next section.

## Global Workspace Models: The Realizations of the GWT

As mentioned earlier in this chapter, Baars' (1993) basic GWT is a functional theory of conscious experience—it does not commit to any (specific) realization. This basic theory makes six theoretical predictions, as mentioned in (Baars, 2017, table 16.1). Based upon it, he proposed seven models with increasingly wider scopes of empirical predictions (for a short overview, see Baars, 2017, table 16.2). Although these models are in accord with specific empirical evidence from the neuroscientific study of consciousness, they are not specifically (or visibly enough) linked to plausible neuroanatomical realizations.

Further research tried to bridge the gap between the mental and realization levels of the mechanistic explanation of consciousness. For a comprehensive review, see (Baars, 2002). Among the GWMs studied in the literature, Shanahan's (2010) dynamic version of a GWM (denoted as DGWM from now on) deserves more attention as it tries to incorporate embodiment within a GW framework. This model roots in his earlier architecture (Shanahan, 2006) that explicitly included the internal stimuli in a GWM. In the remainder of this chapter, the DGWM is discussed.

Shanahan augments an intermediate level of abstraction, namely neural dynamics (ND), between the TLM's two lowest levels of analysis (viz., Lmental and Lrealization; see Chapter 2). Consequently, DGWN puts forth an explication for the (possible) structure of the GW, and an explanation for how this structure serves as a GW. Haikonen (2011) compares various aspects of Baars GWMs to Shanahan's DGWM. Perhaps one of the most important differences between them is that Shanahan emphasizes that GW is an infrastructure of information exchange (wherein competition takes place as well). Hence it is substantially different from Baars' working memory account. Haikonen elaborates on this distinction:

Shanahan's view about the global workspace is different. Firstly, he wishes to distance himself from the theater model by recasting the role of the global workspace. Instead of a working memory, the global workspace should be thought as a communications infrastructure that connects the various autonomous units with each other: "Indeed, unless recast this way, the putative workspace might be mistaken for a dedicated brain region, something akin to the Cartesian theater ridiculed by Dennett, [a place in the brain where 'it all comes together and consciousness happens.']" [(Shanahan, 2010, p. 111)] Shanahan proposes that in the brain, the global workspace consists of the white matter connective core that connects the various brain areas with each other. But this infrastructure is not to be taken only as a transmission medium. According to Shanahan: "GWS is not only the locus of broadcast, but also the arena for competition between rival coalitions and the medium of coupling for the members of those coalitions." [(Shanahan, 2010, p. 147)] This infrastructure has limited capacity and therefore forms a temporally limiting bottleneck; this would explain the serial nature of consciousness. (Haikonen, 2011, pp. 339–340)

Shanahan uses graph theory to characterize possible structures that can be plausible candidates for a putative GW. He seeks a network structure that has two properties: it has specialized autonomous modules, and the modules are efficiently interconnected. Such networks are called small-world structures (SWS) as they share similar mathematical properties with other networks found in the wild . SWSs entered the scientific discourse after Watts and Strogatz (1998) introduced a rewiring algorithm that recursively optimizes the structural properties of a regular graph to show properties of SWSs . SWSs has been studied widely since, and a rich literature asserts that brain networks have small-world properties (SWPs; Bassett & Bullmore, 2006; Sporns & Zwi, 2004; for a more systematic introduction, consult Sporns, 2010, Chapters 3–4). Several rewiring algorithms have been proposed that resemble the natural development of the human brain and can generate SWSs (e.g., see Jarman, Steur, Trengove, Tyukin, & Leeuwen, 2017).

Shanahan (2010, Chapter 4) explains how the coalition can lead to a GW-like structure suitable for broadcast if information. To do so, he takes two steps. First, he investigates formal representations of graphs have the desired structure. He starts with the classic Watts and Strogatz network and suggests an adapted graph wherein highly intraconnected "communities" enhance the modularity of the network (pp. 119-121). He then distinguishes "connector hubs," i.e., the nodes that with "high trans-modular connectivity," and names the links between such hubs the "connective core" (pp. 121-122). Finally, he suggests that the communities themselves can be thought of as smaller SWSs. Hence, he generalizes the network into a "scale-free,"  hierarchical structure, wherein modularity and SWPs are present at different levels of organization—locally and globally (p. 122). These models are shown in Figure 3.4 (adapted from Shanahan, 2010, figs. 4.6-4.8). 

In the second step, he proposes candidate neuroanatomical structures for a presumed GW. More specifically, he suggests the long-range white matter tracts (connecting distant regions of the cortex) as a likely substrate for GW, and the "thalamocortical pathways [that] relay traffic to and from different parts of the cortex, and may also play a role in the putative workspace" (pp. 125-126). Then, he shows that applying the hierarchical SWS introduced in the first step to structural parcellation of the cortex into highly intraconnected brain regions (as in, e.g., Hagmann et al., 2008) yields a similar network structure (p. 126). Finally, he distinguishes a "connective core" within the anatomical network and concludes that it is indeed the possible locus for a neural GW in the brain. This proposal is backed by neuroanatomical findings and mathematical modeling of such network structures, and most importantly, the connective core is capable of manifesting the principal properties of a GW (see Figure 3.1). Shanahan writes,

The connective core of a hierarchically modular network is topologically well placed to realize both broadcast (because influence funnels into and fans out from the centre) and competition (because it acts as a limited capacity bottleneck). So it is an ideal candidate for the anatomical locus of a global workspace. (2010, fig. 4.11 caption)

These models are depicted in Figure 3.5 (adapted from Shanahan, 2010, figs. 4.9-4.11).

Shanahan's DGWM is of the highest value among GWMs for two main reasons. Firstly, it has more explanatory power compared to its predecessors; e.g., it explains embodiment and explicates the inner narrative property of consciousness. Secondly, and most importantly, it is decently anchored to the neural substrate via the intermediate level of abstraction it places between Lmental and Lrealization. The latter point has a remarkable implication: it guarantees a mechanical link between those levels of analysis, hence partitioning the arduous enigma of answering the How questions into two smaller, more feasible problems: explanations at Lmental, and explications of (structural) realization of the GW in the Lrealization. Based upon this, Chapter 4 probes computational implementations of GWMs, and gives a review (and applies) a benchmark to roughly assess the resemblance of such models to human consciousness.


Figure 1 GW as a bottleneck and as a broadcaster (adapted from Franklin et al., 2012, fig. 1)
 
Figure 2 GW architecture (adapted from Shanahan, 2010, fig. 4.1)

 
Figure 3 A schematic diagram of global access. A schematic diagram of global access (adapted from Baars, 2017, fig. 16.1)

# Tables, Graphics, References, and Labels {#ref-labels}

## Tables

In addition to the tables that can be automatically generated from a data frame in **R** that you saw in [R Markdown Basics] using the `kable` function, you can also create tables using _pandoc_. (More information is available at <http://pandoc.org/README.html#tables>.)  This might be useful if you don't have values specifically stored in **R**, but you'd like to display them in table form.  Below is an example.  Pay careful attention to the alignment in the table and hyphens to create the rows and columns.

----------------------------------------------------------------------------------
  Factors                    Correlation between Parents & Child      Inherited
------------------------- ----------------------------------------- --------------
  Education                                -0.49                         Yes
  
  Socio-Economic Status                     0.28                        Slight   
  
  Income                                    0.08                          No
  
  Family Size                               0.18                        Slight
  
  Occupational Prestige                     0.21                        Slight
------------------------- ----------------------------------------- --------------
Table: (\#tab:inher) Correlation of Inheritance Factors for Parents and Child 

We can also create a link to the table by doing the following: Table \@ref(tab:inher).  If you go back to [Loading and exploring data] and look at the `kable` table, we can create a reference to this max delays table too: Table \@ref(tab:maxdelays). The addition of the `(\#tab:inher)` option to the end of the table caption allows us to then make a reference to Table `\@ref(tab:label)`. Note that this reference could appear anywhere throughout the document after the table has appeared.  

<!-- We will next explore ways to create this label-ref link using figures. -->

\clearpage

<!-- clearpage ends the page, and also dumps out all floats.
  Floats are things like tables and figures. -->


## Figures

If your thesis has a lot of figures, _R Markdown_ might behave better for you than that other word processor.  One perk is that it will automatically number the figures accordingly in each chapter.    You'll also be able to create a label for each figure, add a caption, and then reference the figure in a way similar to what we saw with tables earlier.  If you label your figures, you can move the figures around and _R Markdown_ will automatically adjust the numbering for you.  No need for you to remember!  So that you don't have to get too far into LaTeX to do this, a couple **R** functions have been created for you to assist.  You'll see their use below.

<!--
One thing that may be annoying is the way _R Markdown_ handles "floats" like tables and figures (it's really \LaTeX's fault). \LaTeX\ will try to find the best place to put your object based on the text around it and until you're really, truly done writing you should just leave it where it lies. There are some optional arguments specified in the options parameter of the `label` function.  If you need to shift your figure around, it might be good to look here on tweaking the options argument:  <https://en.wikibooks.org/wiki/LaTeX/Floats,_Figures_and_Captions>

If you need a graphic or tabular material to be part of the text, you can just put it inline. If you need it to appear in the list of figures or tables, it should be placed in a code chunk.
-->


In the **R** chunk below, we will load in a picture stored as `reed.jpg` in our main directory.  We then give it the caption of "Reed logo", the label of "reedlogo", and specify that this is a figure.  Make note of the different **R** chunk options that are given in the R Markdown file (not shown in the knitted document).

```{r reedlogo, fig.cap="Reed logo"}
include_graphics(path = "figure/reed.jpg")
```

Here is a reference to the Reed logo: Figure \@ref(fig:reedlogo).  Note the use of the `fig:` code here.  By naming the **R** chunk that contains the figure, we can then reference that figure later as done in the first sentence here.  We can also specify the caption for the figure via the R chunk option `fig.cap`.

\clearpage 

<!-- starts a new page and stops trying to place floats such as tables and figures -->

Below we will investigate how to save the output of an **R** plot and label it in a way similar to that done above.  Recall the `flights` dataset from Chapter \@ref(rmd-basics).  (Note that we've shown a different way to reference a section or chapter here.)  We will next explore a bar graph with the mean flight departure delays by airline from Portland for 2014.  Note also the use of the `scale` parameter which is discussed on the next page.

```{r delaysboxplot, warnings=FALSE, messages=FALSE, fig.cap="Mean Delays by Airline", fig.width=6}
flights %>% group_by(carrier) %>%
  summarize(mean_dep_delay = mean(dep_delay)) %>%
  ggplot(aes(x = carrier, y = mean_dep_delay)) +
  geom_bar(position = "identity", stat = "identity", fill = "red")
```

Here is a reference to this image: Figure \@ref(fig:delaysboxplot).

A table linking these carrier codes to airline names is available at <https://github.com/ismayc/pnwflights14/blob/master/data/airlines.csv>.

\clearpage

Next, we will explore the use of the `out.extra` chunk option, which can be used to shrink or expand an image loaded from a file by specifying `"scale= "`. Here we use the mathematical graph stored in the "subdivision.pdf" file.

```{r subd, results="asis", echo=FALSE, fig.cap="Subdiv. graph", out.extra="scale=0.75"}
include_graphics("figure/subdivision.pdf")
```

Here is a reference to this image: Figure \@ref(fig:subd).  Note that `echo=FALSE` is specified so that the **R** code is hidden in the document.

**More Figure Stuff**

Lastly, we will explore how to rotate and enlarge figures using the `out.extra` chunk option.  (Currently this only works in the PDF version of the book.)

```{r subd2, results="asis", echo=FALSE, out.extra="angle=180, scale=1.1", fig.cap="A Larger Figure, Flipped Upside Down"}
include_graphics("figure/subdivision.pdf")
```

As another example, here is a reference: Figure \@ref(fig:subd2).  

## Footnotes and Endnotes

You might want to footnote something. ^[footnote text] The footnote will be in a smaller font and placed appropriately. Endnotes work in much the same way. More information can be found about both on the CUS site or feel free to reach out to <data@reed.edu>.

## Bibliographies

Of course you will need to cite things, and you will probably accumulate an armful of sources. There are a variety of tools available for creating a bibliography database (stored with the .bib extension).  In addition to BibTeX suggested below, you may want to consider using the free and easy-to-use tool called Zotero.  The Reed librarians have created Zotero documentation at <http://libguides.reed.edu/citation/zotero>.  In addition, a tutorial is available from Middlebury College at <http://sites.middlebury.edu/zoteromiddlebury/>.

_R Markdown_ uses _pandoc_ (<http://pandoc.org/>) to build its bibliographies.  One nice caveat of this is that you won't have to do a second compile to load in references as standard LaTeX requires. To cite references in your thesis (after creating your bibliography database), place the reference name inside square brackets and precede it by the "at" symbol.  For example, here's a reference to a book about worrying: `@key` is @Molina1994 and `[@key]` is [-@reedweb2007 p. 85; @noble2002; @Molina1994].  This `Molina1994` entry appears in a file called `thesis.bib` in the `bib` folder.  This bibliography database file was created by a program called BibTeX.  You can call this file something else if you like (look at the YAML header in the main .Rmd file) and, by default, is to placed in the `bib` folder.  

For more information about BibTeX and bibliographies, see our CUS site (<http://web.reed.edu/cis/help/latex/index.html>)^[@reedweb2007]. There are three pages on this topic:  _bibtex_ (which talks about using BibTeX, at <http://web.reed.edu/cis/help/latex/bibtex.html>), _bibtexstyles_ (about how to find and use the bibliography style that best suits your needs, at <http://web.reed.edu/cis/help/latex/bibtexstyles.html>) and _bibman_ (which covers how to make and maintain a bibliography by hand, without BibTeX, at <http://web.reed.edu/cis/help/latex/bibman.html>). The last page will not be useful unless you have only a few sources.

If you look at the YAML header at the top of the main .Rmd file you can see that we can specify the style of the bibliography by referencing the appropriate csl file.  You can download a variety of different style files at <https://www.zotero.org/styles>.  Make sure to download the file into the csl folder.

**Tips for Bibliographies**

- Like with thesis formatting, the sooner you start compiling your bibliography for something as large as thesis, the better. Typing in source after source is mind-numbing enough; do you really want to do it for hours on end in late April? Think of it as procrastination.
- The cite key (a citation's label) needs to be unique from the other entries.
- When you have more than one author or editor, you need to separate each author's name by the word "and" e.g. `Author = {Noble, Sam and Youngberg, Jessica},`.
- Bibliographies made using BibTeX (whether manually or using a manager) accept LaTeX markup, so you can italicize and add symbols as necessary.
- To force capitalization in an article title or where all lowercase is generally used, bracket the capital letter in curly braces.
- You can add a Reed Thesis citation^[@noble2002] option. The best way to do this is to use the phdthesis type of citation, and use the optional "type" field to enter "Reed thesis" or "Undergraduate thesis." 

## Anything else?

If you'd like to see examples of other things in this template, please contact the Data @ Reed team (email <data@reed.edu>) with your suggestions. We love to see people using _R Markdown_ for their theses, and are happy to help.

